input {
	file {
		path => "/dev/elastic/pipelines-logstash/events.log"
		start_position => "beginning"
		type => "access"
	}
	stdin {
		codec => json
	}

	http {
		host => "127.0.0.1"
		port => 8080
		type => "access"
	}
}

filter {
	if [headers][request_uri] =~ "error" or [path] =~ "errors" {
		mutate {
			replace => { type => "error" }
		}
	} else {
		mutate {
			replace => { type => "access" }
		}
	}

	grok {
	#	match => { "message" => "%{IP:ip_address} %{USER:identity} %{USER:auth} \[%{HTTPDATE:req_ts}\] \"%{WORD:http_verb} %{URIPATHPARAM:req_path} %{NOTSPACE:protocolVersion}\" %{INT:http_status:int} %{INT:number_bytes_transfer:int}" }

		match => { "message" => '%{HTTPD_COMMONLOG} "%{GREEDYDATA:referrer}" "%{GREEDYDATA:useragent}"' }
	}

	# Admin pages
	if [request] =~ /^\/admin\// {
		drop { }
	}

	# Static files
	if [request] =~ /^\/js\//
	   or [request] =~ /^\/css\//
	   or [request] in [ "/robots.txt", "/favicon.ico" ] {
	   drop { }
	}

	# Crawlers
	if [ui][device] == "Spider" { 
		drop { }
	}

	if "_grokparsefailure" in [tags] {
		mutate {
	       		replace => { erro_parse_grok => "erro parse grok - verificar!!!!" }
	       	}
	        # drop { } # delete the message with error
	}

	useragent {
		source => "agent"
		target => "ua"
	}

	date {
		match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
		remove_field => [ "timestamp" ]
	}

	geoip {
		source => "clientip"
	}

	mutate {
		remove_field => [ "hearders", "@version", "host" ]
	}
}

output {
	stdout {
		codec => rubydebug
	}

	file {
		path => "%{type}.txt"
	}

	elasticsearch {
		hosts => [ "localhost:9200" ]
		#index => "%{type}-%{+YYYY.MM.dd}"
		document_type => "default"
		http_compression => true
	}
}

